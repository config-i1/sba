<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.3 Properties of estimators | Statistics for Business Analytics</title>
  <meta name="description" content="This book covers the main principles of statistics for Business Analytics, focusing on the application side and how analytics and forecasting can be done with conventional statistical models." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.3 Properties of estimators | Statistics for Business Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book covers the main principles of statistics for Business Analytics, focusing on the application side and how analytics and forecasting can be done with conventional statistical models." />
  <meta name="github-repo" content="config-i1/sba" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.3 Properties of estimators | Statistics for Business Analytics" />
  
  <meta name="twitter:description" content="This book covers the main principles of statistics for Business Analytics, focusing on the application side and how analytics and forecasting can be done with conventional statistical models." />
  

<meta name="author" content="Ivan Svetunkov" />


<meta name="date" content="2022-01-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="CLT.html"/>
<link rel="next" href="uncertaintyData.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script async defer src="https://hypothes.is/embed.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XH37Z8VYP8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XH37Z8VYP8');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics for Business Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="what-is-model.html"><a href="what-is-model.html"><i class="fa fa-check"></i><b>1.1</b> What is model?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="what-is-model.html"><a href="what-is-model.html#modelsMethods"><i class="fa fa-check"></i><b>1.1.1</b> Models, methods et al.Â </a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scales.html"><a href="scales.html"><i class="fa fa-check"></i><b>1.2</b> Scales of information</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="scales.html"><a href="scales.html#nominal-scale"><i class="fa fa-check"></i><b>1.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="1.2.2" data-path="scales.html"><a href="scales.html#ordinal-scale"><i class="fa fa-check"></i><b>1.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="1.2.3" data-path="scales.html"><a href="scales.html#interval-scale"><i class="fa fa-check"></i><b>1.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="1.2.4" data-path="scales.html"><a href="scales.html#ratio-scale"><i class="fa fa-check"></i><b>1.2.4</b> Ratio scale</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="sourcesOfUncertainty.html"><a href="sourcesOfUncertainty.html"><i class="fa fa-check"></i><b>1.3</b> Sources of uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="dataAnalysis.html"><a href="dataAnalysis.html"><i class="fa fa-check"></i><b>2</b> Preliminary data analysis</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dataAnalysisNumerical.html"><a href="dataAnalysisNumerical.html"><i class="fa fa-check"></i><b>2.1</b> Numerical analysis</a></li>
<li class="chapter" data-level="2.2" data-path="dataAnalysisGraphical.html"><a href="dataAnalysisGraphical.html"><i class="fa fa-check"></i><b>2.2</b> Graphical analysis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>3</b> Continuous distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distributionsNormal.html"><a href="distributionsNormal.html"><i class="fa fa-check"></i><b>3.1</b> Normal distribution</a></li>
<li class="chapter" data-level="3.2" data-path="distributionsLaplace.html"><a href="distributionsLaplace.html"><i class="fa fa-check"></i><b>3.2</b> Laplace distribution</a></li>
<li class="chapter" data-level="3.3" data-path="s-distribution.html"><a href="s-distribution.html"><i class="fa fa-check"></i><b>3.3</b> S distribution</a></li>
<li class="chapter" data-level="3.4" data-path="distributionsGeneralisedNormal.html"><a href="distributionsGeneralisedNormal.html"><i class="fa fa-check"></i><b>3.4</b> Generalised Normal distribution</a></li>
<li class="chapter" data-level="3.5" data-path="distributionsALaplace.html"><a href="distributionsALaplace.html"><i class="fa fa-check"></i><b>3.5</b> Asymmetric Laplace distribution</a></li>
<li class="chapter" data-level="3.6" data-path="log-normal-log-laplace-log-s-and-log-gn-distributions.html"><a href="log-normal-log-laplace-log-s-and-log-gn-distributions.html"><i class="fa fa-check"></i><b>3.6</b> Log Normal, Log Laplace, Log S and Log GN distributions</a></li>
<li class="chapter" data-level="3.7" data-path="IGDistribution.html"><a href="IGDistribution.html"><i class="fa fa-check"></i><b>3.7</b> Inverse Gaussian distribution</a></li>
<li class="chapter" data-level="3.8" data-path="GammaDistribution.html"><a href="GammaDistribution.html"><i class="fa fa-check"></i><b>3.8</b> Gamma distribution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="PopulationSampling.html"><a href="PopulationSampling.html"><i class="fa fa-check"></i><b>4</b> Population and sampling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="LLN.html"><a href="LLN.html"><i class="fa fa-check"></i><b>4.1</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="4.2" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>4.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="4.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html"><i class="fa fa-check"></i><b>4.3</b> Properties of estimators</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesBias"><i class="fa fa-check"></i><b>4.3.1</b> Bias</a></li>
<li class="chapter" data-level="4.3.2" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesEfficiency"><i class="fa fa-check"></i><b>4.3.2</b> Efficiency</a></li>
<li class="chapter" data-level="4.3.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesConsistency"><i class="fa fa-check"></i><b>4.3.3</b> Consistency</a></li>
<li class="chapter" data-level="4.3.4" data-path="estimatesProperties.html"><a href="estimatesProperties.html#asymptoticNormality"><i class="fa fa-check"></i><b>4.3.4</b> Asymptotic normality</a></li>
<li class="chapter" data-level="4.3.5" data-path="estimatesProperties.html"><a href="estimatesProperties.html#efficiencyVSBias"><i class="fa fa-check"></i><b>4.3.5</b> Why having biased estimate can be better than having the inefficient one?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="uncertaintyData.html"><a href="uncertaintyData.html"><i class="fa fa-check"></i><b>5</b> Sample related uncertainty</a>
<ul>
<li class="chapter" data-level="5.1" data-path="confidenceInterval.html"><a href="confidenceInterval.html"><i class="fa fa-check"></i><b>5.1</b> Confidence interval</a></li>
<li class="chapter" data-level="5.2" data-path="confidenceIntervalsPrediction.html"><a href="confidenceIntervalsPrediction.html"><i class="fa fa-check"></i><b>5.2</b> Prediction interval</a></li>
<li class="chapter" data-level="5.3" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html"><i class="fa fa-check"></i><b>5.3</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html#hypothesisTestingMistakes"><i class="fa fa-check"></i><b>5.3.1</b> Common mistakes related to hypothesis testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>6</b> Measuring relations between variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="nominal-scale-1.html"><a href="nominal-scale-1.html"><i class="fa fa-check"></i><b>6.1</b> Nominal scale</a></li>
<li class="chapter" data-level="6.2" data-path="ordinal-scale-1.html"><a href="ordinal-scale-1.html"><i class="fa fa-check"></i><b>6.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="6.3" data-path="correlationCoefficient.html"><a href="correlationCoefficient.html"><i class="fa fa-check"></i><b>6.3</b> Numerical scale</a></li>
<li class="chapter" data-level="6.4" data-path="correlationsMixed.html"><a href="correlationsMixed.html"><i class="fa fa-check"></i><b>6.4</b> Mixed scales</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simpleLinearRegression.html"><a href="simpleLinearRegression.html"><i class="fa fa-check"></i><b>7</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="OLS.html"><a href="OLS.html"><i class="fa fa-check"></i><b>7.1</b> Ordinary Least Squares (OLS)</a></li>
<li class="chapter" data-level="7.2" data-path="linearRegressionSimpleQualityOfFit.html"><a href="linearRegressionSimpleQualityOfFit.html"><i class="fa fa-check"></i><b>7.2</b> Quality of the fit</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linearRegression.html"><a href="linearRegression.html"><i class="fa fa-check"></i><b>8</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ols-estimation.html"><a href="ols-estimation.html"><i class="fa fa-check"></i><b>8.1</b> OLS estimation</a></li>
<li class="chapter" data-level="8.2" data-path="linearRegressionMultipleQualityOfFit.html"><a href="linearRegressionMultipleQualityOfFit.html"><i class="fa fa-check"></i><b>8.2</b> Quality of the fit</a></li>
<li class="chapter" data-level="8.3" data-path="interpretation-of-parameters.html"><a href="interpretation-of-parameters.html"><i class="fa fa-check"></i><b>8.3</b> Interpretation of parameters</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="uncertaintyParameters.html"><a href="uncertaintyParameters.html"><i class="fa fa-check"></i><b>9</b> Uncertainty in regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>9.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>9.2</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#regression-parameters"><i class="fa fa-check"></i><b>9.2.1</b> Regression parameters</a></li>
<li class="chapter" data-level="9.2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#regression-line"><i class="fa fa-check"></i><b>9.2.2</b> Regression line</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regression-line-uncertainty.html"><a href="regression-line-uncertainty.html"><i class="fa fa-check"></i><b>9.3</b> Regression line uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="dummyVariables.html"><a href="dummyVariables.html"><i class="fa fa-check"></i><b>10</b> Regression with categorical variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="dummy-variables-for-the-intercept.html"><a href="dummy-variables-for-the-intercept.html"><i class="fa fa-check"></i><b>10.1</b> Dummy variables for the intercept</a></li>
<li class="chapter" data-level="10.2" data-path="categorical-variables-for-the-slope.html"><a href="categorical-variables-for-the-slope.html"><i class="fa fa-check"></i><b>10.2</b> Categorical variables for the slope</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variablesTransformations.html"><a href="variablesTransformations.html"><i class="fa fa-check"></i><b>11</b> Variables transformations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="example-of-application.html"><a href="example-of-application.html"><i class="fa fa-check"></i><b>11.1</b> Example of application</a></li>
<li class="chapter" data-level="11.2" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html"><i class="fa fa-check"></i><b>11.2</b> Types of variables transformations</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#linear-model"><i class="fa fa-check"></i><b>11.2.1</b> Linear model</a></li>
<li class="chapter" data-level="11.2.2" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#log-log-model"><i class="fa fa-check"></i><b>11.2.2</b> Log-Log model</a></li>
<li class="chapter" data-level="11.2.3" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#log-linear-model"><i class="fa fa-check"></i><b>11.2.3</b> Log-linear model</a></li>
<li class="chapter" data-level="11.2.4" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#linear-log-model"><i class="fa fa-check"></i><b>11.2.4</b> Linear-Log model</a></li>
<li class="chapter" data-level="11.2.5" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#square-root-model"><i class="fa fa-check"></i><b>11.2.5</b> Square root model</a></li>
<li class="chapter" data-level="11.2.6" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#quadratic-model"><i class="fa fa-check"></i><b>11.2.6</b> Quadratic model</a></li>
<li class="chapter" data-level="11.2.7" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#polynomial-model"><i class="fa fa-check"></i><b>11.2.7</b> Polynomial model</a></li>
<li class="chapter" data-level="11.2.8" data-path="types-of-variables-transformations.html"><a href="types-of-variables-transformations.html#box-cox"><i class="fa fa-check"></i><b>11.2.8</b> Box-Cox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>12</b> Statistical models assumptions</a>
<ul>
<li class="chapter" data-level="12.1" data-path="assumptionsCorrectModel.html"><a href="assumptionsCorrectModel.html"><i class="fa fa-check"></i><b>12.1</b> Model is correctly specified</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="assumptionsCorrectModel.html"><a href="assumptionsCorrectModel.html#assumptionsCorrectModelOmitted"><i class="fa fa-check"></i><b>12.1.1</b> Omitted variables</a></li>
<li class="chapter" data-level="12.1.2" data-path="assumptionsCorrectModel.html"><a href="assumptionsCorrectModel.html#assumptionsCorrectModelRedundant"><i class="fa fa-check"></i><b>12.1.2</b> Redundant variables</a></li>
<li class="chapter" data-level="12.1.3" data-path="assumptionsCorrectModel.html"><a href="assumptionsCorrectModel.html#assumptionsCorrectModelTransformations"><i class="fa fa-check"></i><b>12.1.3</b> Transformations</a></li>
<li class="chapter" data-level="12.1.4" data-path="assumptionsCorrectModel.html"><a href="assumptionsCorrectModel.html#assumptionsCorrectModelOutliers"><i class="fa fa-check"></i><b>12.1.4</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html"><i class="fa fa-check"></i><b>12.2</b> Residuals are i.i.d.</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html#assumptionsResidualsAreIIDAutocorrelations"><i class="fa fa-check"></i><b>12.2.1</b> No autocorrelations</a></li>
<li class="chapter" data-level="12.2.2" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html#assumptionsResidualsAreIIDHomoscedasticity"><i class="fa fa-check"></i><b>12.2.2</b> Homoscedastic residuals</a></li>
<li class="chapter" data-level="12.2.3" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html#assumptionsResidualsAreIIDMean"><i class="fa fa-check"></i><b>12.2.3</b> Mean of residuals</a></li>
<li class="chapter" data-level="12.2.4" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html#assumptionsDistribution"><i class="fa fa-check"></i><b>12.2.4</b> Distributional assumptions</a></li>
<li class="chapter" data-level="12.2.5" data-path="assumptionsResidualsAreIID.html"><a href="assumptionsResidualsAreIID.html#assumptionsDistributionFixed"><i class="fa fa-check"></i><b>12.2.5</b> Distribution does not change</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="assumptionsXreg.html"><a href="assumptionsXreg.html"><i class="fa fa-check"></i><b>12.3</b> The explanatory variables are not correlated with anything but the response variable</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="assumptionsXreg.html"><a href="assumptionsXreg.html#assumptionsXregMulti"><i class="fa fa-check"></i><b>12.3.1</b> Multicollinearity</a></li>
<li class="chapter" data-level="12.3.2" data-path="assumptionsXreg.html"><a href="assumptionsXreg.html#assumptionsXregEndogeneity"><i class="fa fa-check"></i><b>12.3.2</b> Engogeneity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html"><i class="fa fa-check"></i><b>13</b> Likelihood Approach</a>
<ul>
<li class="chapter" data-level="13.1" data-path="an-example-in-r.html"><a href="an-example-in-r.html"><i class="fa fa-check"></i><b>13.1</b> An example in R</a></li>
<li class="chapter" data-level="13.2" data-path="likelihoodApproachMaths.html"><a href="likelihoodApproachMaths.html"><i class="fa fa-check"></i><b>13.2</b> Mathematical explanation</a></li>
<li class="chapter" data-level="13.3" data-path="statisticsNumberOfParameters.html"><a href="statisticsNumberOfParameters.html"><i class="fa fa-check"></i><b>13.3</b> Calculating number of parameters in models</a></li>
<li class="chapter" data-level="13.4" data-path="informationCriteria.html"><a href="informationCriteria.html"><i class="fa fa-check"></i><b>13.4</b> Information criteria</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="informationCriteria.html"><a href="informationCriteria.html#informationCriteriaIdea"><i class="fa fa-check"></i><b>13.4.1</b> The idea</a></li>
<li class="chapter" data-level="13.4.2" data-path="informationCriteria.html"><a href="informationCriteria.html#informationCriteriaMistakes"><i class="fa fa-check"></i><b>13.4.2</b> Common confusions related to information criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="uncertaintyModel.html"><a href="uncertaintyModel.html"><i class="fa fa-check"></i><b>14</b> Uncertainty about the model form</a>
<ul>
<li class="chapter" data-level="14.1" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html"><i class="fa fa-check"></i><b>14.1</b> Bias-variance tradeoff</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#graphical-explanation"><i class="fa fa-check"></i><b>14.1.1</b> Graphical explanation</a></li>
<li class="chapter" data-level="14.1.2" data-path="bias-variance-tradeoff.html"><a href="bias-variance-tradeoff.html#mathematical-explanation"><i class="fa fa-check"></i><b>14.1.2</b> Mathematical explanation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics for Business Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b><a href="open.html#open">Open Review</a></b>. I want your feedback to make the book better for you and other readers. To add your annotation, <span style="background-color: #3297FD; color: white">select some text</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. To see the annotations of others, click the button in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="estimatesProperties" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Properties of estimators</h2>
<p>Before we move further, we need to agree what the term âestimatorâ means, which will be used several times further in this textbook:</p>
<ul>
<li><strong>Estimate</strong> of a parameter is an in sample result of application of a statistical procedure to the data for obtaining some coefficients of a model. The value calculated using the arithmetic mean would be an estimate of the population mean;</li>
<li><strong>Estimator</strong> is the rule for calculating estimates of parameters based on a sample of data. For example, arithmetic mean is an estimator of the population mean. Another example would be method of Ordinary Least Squares, which is a rule for producing estimates of parameters of a regression model and thus an estimator.</li>
</ul>
<p>In this section, we discuss such terms as <strong>bias</strong>, <strong>efficiency</strong> and <strong>consistency</strong> of estimates of parameters, which are directly related to <a href="LLN.html#LLN">LLN</a> and <a href="CLT.html#CLT">CLT</a>. Although there are strict statistical definitions of the aforementioned terms (you can easily find them in Wikipedia or anywhere else), I do not want to copy-paste them here, because there are only a couple of important points worth mentioning in our context.</p>
<p>Note that all the discussions in this chapter relate to <strong>the estimates of parameters</strong>, not to the distribution of a random variable itself. A common mistake that students make when studying statistics, is that they think that the properties apply to the variable <span class="math inline">\(y_j\)</span> instead of the estimate of its parameters (e.g.Â mean of <span class="math inline">\(y_j\)</span>).</p>
<div id="estimatesPropertiesBias" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Bias</h3>
<p><strong>Bias</strong> refers to the expected difference between the estimated value of parameter (on a specific sample) and the â<a href="intro.html#intro">true</a>â one (in the true model). Having unbiased estimates of parameters is important because they should lead to more accurate forecasts (at least in theory). For example, if the estimated parameter is equal to zero, while in fact it should be 0.5, then the model would not take the provided information into account correctly and as a result will produce less accurate point forecasts and incorrect prediction intervals. In inventory context this may mean that we constantly order 100 units less than needed only because the parameter is lower than it should be.</p>
<p>The classical example of bias in statistics is the estimation of variance in sample. The following formula gives biased estimate of variance in sample:
<span class="math display" id="eq:varianceBiased">\[\begin{equation}
    \mathrm{V}(y) = \frac{1}{T} \sum_{j=1}^n \left( y_j - \bar{y} \right)^2,
    \tag{4.1}
\end{equation}\]</span>
where <span class="math inline">\(T\)</span> is the sample size and <span class="math inline">\(\bar{y} = \frac{1}{T} \sum_{j=1}^n y_j\)</span> is the mean of the data. There is a lot of proofs in the literature of this issue (even <span class="citation"><a href="#ref-WikipediaVarianceBias2020" role="doc-biblioref">Wikipedia</a> (<a href="#ref-WikipediaVarianceBias2020" role="doc-biblioref">2020a</a>)</span> has one), we will not spend time on that. Instead, we will see this effect in the following simple simulation experiment:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="estimatesProperties.html#cb47-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb47-2"><a href="estimatesProperties.html#cb47-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb47-3"><a href="estimatesProperties.html#cb47-3" aria-hidden="true" tabindex="-1"></a>nIterations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb47-4"><a href="estimatesProperties.html#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data from normal distribution, 10,000 observations</span></span>
<span id="cb47-5"><a href="estimatesProperties.html#cb47-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>,mu,sigma)</span>
<span id="cb47-6"><a href="estimatesProperties.html#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This is the function, which will calculate the two variances</span></span>
<span id="cb47-7"><a href="estimatesProperties.html#cb47-7" aria-hidden="true" tabindex="-1"></a>varFunction <span class="ot">&lt;-</span> <span class="cf">function</span>(y){</span>
<span id="cb47-8"><a href="estimatesProperties.html#cb47-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(<span class="fu">c</span>(<span class="fu">var</span>(y), <span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb47-9"><a href="estimatesProperties.html#cb47-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb47-10"><a href="estimatesProperties.html#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate biased and unbiased variances for the sample of 30 observations,</span></span>
<span id="cb47-11"><a href="estimatesProperties.html#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># repeat nIterations times</span></span>
<span id="cb47-12"><a href="estimatesProperties.html#cb47-12" aria-hidden="true" tabindex="-1"></a>varValues <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nIterations, <span class="fu">varFunction</span>(<span class="fu">sample</span>(y,<span class="dv">30</span>)))</span></code></pre></div>
<p>This way we have generated 1000 samples with 30 observations and calculated variances using the formulae <a href="estimatesProperties.html#eq:varianceBiased">(4.1)</a> and the corrected one for each step. Now we can plot it in order to see how it worked out:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="estimatesProperties.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb48-2"><a href="estimatesProperties.html#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of the biased estimate</span></span>
<span id="cb48-3"><a href="estimatesProperties.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(varValues[<span class="dv">2</span>,], <span class="at">xlab=</span><span class="st">&quot;V(y)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;y&quot;</span>, <span class="at">main=</span><span class="st">&quot;Biased estimate of V(y)&quot;</span>)</span>
<span id="cb48-4"><a href="estimatesProperties.html#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(varValues[<span class="dv">2</span>,]), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb48-5"><a href="estimatesProperties.html#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>,<span class="at">legend=</span><span class="fu">TeX</span>(<span class="fu">paste0</span>(<span class="st">&quot;E$</span><span class="sc">\\</span><span class="st">left(V(y)</span><span class="sc">\\</span><span class="st">right)$=&quot;</span>,<span class="fu">round</span>(<span class="fu">mean</span>(varValues[<span class="dv">2</span>,]),<span class="dv">2</span>))),<span class="at">lwd=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb48-6"><a href="estimatesProperties.html#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="estimatesProperties.html#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of unbiased estimate</span></span>
<span id="cb48-8"><a href="estimatesProperties.html#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(varValues[<span class="dv">1</span>,], <span class="at">xlab=</span><span class="st">&quot;V(y)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;y&quot;</span>, <span class="at">main=</span><span class="st">&quot;Unbiased estimate of V(y)&quot;</span>)</span>
<span id="cb48-9"><a href="estimatesProperties.html#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(varValues[<span class="dv">1</span>,]), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb48-10"><a href="estimatesProperties.html#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>,<span class="at">legend=</span><span class="fu">TeX</span>(<span class="fu">paste0</span>(<span class="st">&quot;E$</span><span class="sc">\\</span><span class="st">left(V(y)</span><span class="sc">\\</span><span class="st">right)$=&quot;</span>,<span class="fu">round</span>(<span class="fu">mean</span>(varValues[<span class="dv">1</span>,]),<span class="dv">2</span>))),<span class="at">lwd=</span><span class="dv">1</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-14"></span>
<img src="adam_files/figure-html/unnamed-chunk-14-1.png" alt="Histograms for biased and unbiased estimates of variance." width="672" />
<p class="caption">
Figure 4.4: Histograms for biased and unbiased estimates of variance.
</p>
</div>
<p>Every run of this experiment will produce different plots, but typically what we will see is that, the biased estimate of variance (the histogram on the right hand side of the plot) will have lower mean than the unbiased one. This is the graphical example of the effect of not taking the number of estimated parameters into account. The correct formula for the unbiased estimate of variance is:
<span class="math display" id="eq:varianceUnBiased">\[\begin{equation}
    s^2 = \frac{1}{T-k} \sum_{j=1}^n \left( y_j - \bar{y} \right)^2,
    \tag{4.2}
\end{equation}\]</span>
where <span class="math inline">\(k\)</span> is the number of all independent estimated parameters. In this simple example <span class="math inline">\(k=1\)</span>, because we only estimate mean (the variance is based on it). Analysing the formulae <a href="estimatesProperties.html#eq:varianceBiased">(4.1)</a> and <a href="estimatesProperties.html#eq:varianceUnBiased">(4.2)</a>, we can say that with the increase of the sample size, the bias will disappear and the two formulae will give almost the same results: when the sample size <span class="math inline">\(T\)</span> becomes big enough, the difference between the two becomes negligible. This is the graphical presentation of the bias in the estimator.</p>
</div>
<div id="estimatesPropertiesEfficiency" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Efficiency</h3>
<p><strong>Efficiency</strong> means, if the sample size increases, then the estimated parameters will not change substantially, they will vary in a narrow range (variance of estimates will be small). In the case with inefficient estimates the increase of sample size from 50 to 51 observations may lead to the change of a parameter from 0.1 to, letâs say, 10. This is bad because the values of parameters usually influence both point forecasts and prediction intervals. As a result the inventory decision may differ radically from day to day. For example, we may decide that we urgently need 1000 units of product on Monday, and order it just to realise on Tuesday that we only need 100. Obviously this is an exaggeration, but no one wants to deal with such an erratically behaving model, so we need to have efficient estimates of parameters.</p>
<p>Another classical example of not efficient estimator is the median, when used on the data that follows Normal distribution. Here is a simple experiment demonstrating the idea:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="estimatesProperties.html#cb49-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb49-2"><a href="estimatesProperties.html#cb49-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb49-3"><a href="estimatesProperties.html#cb49-3" aria-hidden="true" tabindex="-1"></a>nIterations <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb49-4"><a href="estimatesProperties.html#cb49-4" aria-hidden="true" tabindex="-1"></a>obs <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb49-5"><a href="estimatesProperties.html#cb49-5" aria-hidden="true" tabindex="-1"></a>varMeanValues <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;numeric&quot;</span>,obs)</span>
<span id="cb49-6"><a href="estimatesProperties.html#cb49-6" aria-hidden="true" tabindex="-1"></a>varMedianValues <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;numeric&quot;</span>,obs)</span>
<span id="cb49-7"><a href="estimatesProperties.html#cb49-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100000</span>,mu,sigma)</span>
<span id="cb49-8"><a href="estimatesProperties.html#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>obs){</span>
<span id="cb49-9"><a href="estimatesProperties.html#cb49-9" aria-hidden="true" tabindex="-1"></a>    ySample <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nIterations,<span class="fu">sample</span>(y,i<span class="sc">*</span><span class="dv">100</span>))</span>
<span id="cb49-10"><a href="estimatesProperties.html#cb49-10" aria-hidden="true" tabindex="-1"></a>    varMeanValues[i] <span class="ot">&lt;-</span> <span class="fu">var</span>(<span class="fu">apply</span>(ySample,<span class="dv">2</span>,mean))</span>
<span id="cb49-11"><a href="estimatesProperties.html#cb49-11" aria-hidden="true" tabindex="-1"></a>    varMedianValues[i] <span class="ot">&lt;-</span> <span class="fu">var</span>(<span class="fu">apply</span>(ySample,<span class="dv">2</span>,median))</span>
<span id="cb49-12"><a href="estimatesProperties.html#cb49-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>In order to establish the efficiency of the estimators, we will take their variances and look at the ratio of mean over median. If both are equally efficient, then this ratio will be equal to one. If the mean is more efficient than the median, then the ratio will be less than one:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="estimatesProperties.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">6</span>)</span>
<span id="cb50-2"><a href="estimatesProperties.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span><span class="sc">*</span><span class="dv">100</span>,varMeanValues<span class="sc">/</span>varMedianValues, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Sample size&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Relative efficiency&quot;</span>)</span>
<span id="cb50-3"><a href="estimatesProperties.html#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">1</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:statsEfficiecny"></span>
<img src="images/02-statistics-efficiency.png" alt="An example of a relatively inefficient estimator."  />
<p class="caption">
Figure 4.5: An example of a relatively inefficient estimator.
</p>
</div>
<p>What we should typically see on this graph, is that the black line should be below the red one, indicating that the variance of mean is lower than the variance of the median. This means that mean is more efficient estimator of the true location of the distribution <span class="math inline">\(\mu\)</span> than the median. In fact, it is easy to proove that asymptotically the mean will be 1.57 times more efficient than median <span class="citation">(<a href="#ref-WikipediaMedianEfficiency2020" role="doc-biblioref">Wikipedia, 2020b</a>)</span> (so, the line should converge approximately to the value of 0.64).</p>
</div>
<div id="estimatesPropertiesConsistency" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Consistency</h3>
<p><strong>Consistency</strong> means that our estimates of parameters will get closer to the stable values (true value in the population) with the increase of the sample size. This follows directly from <a href="#LLNandCLT">LLN</a> and is important because in the opposite case estimates of parameters will diverge and become less and less realistic. This once again influences both point forecasts and prediction intervals, which will be less meaningful than they should have been. In a way consistency means that with the increase of the sample size the parameters will become more efficient and less biased. This in turn means that the more observations we have, the better.</p>
<p>An example of inconsistent estimator is Chebyshev (or max norm) metric. It is formulated the following way:
<span class="math display" id="eq:chebyshevNorm">\[\begin{equation}
    \mathrm{LMax} = \max \left(|y_1-\hat{y}|, |y_2-\hat{y}|, \dots, |y_n-\hat{y}| \right).
    \tag{4.3}
\end{equation}\]</span>
Minimising this norm, we can get an estimate <span class="math inline">\(\hat{y}\)</span> of the location parameter <span class="math inline">\(\mu\)</span>. The simulation experiment becomes a bit more tricky in this situation, but here is the code to generate the estimates of the location parameter:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="estimatesProperties.html#cb51-1" aria-hidden="true" tabindex="-1"></a>LMax <span class="ot">&lt;-</span> <span class="cf">function</span>(y){</span>
<span id="cb51-2"><a href="estimatesProperties.html#cb51-2" aria-hidden="true" tabindex="-1"></a>    estimator <span class="ot">&lt;-</span> <span class="cf">function</span>(par){</span>
<span id="cb51-3"><a href="estimatesProperties.html#cb51-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(<span class="fu">max</span>(<span class="fu">abs</span>(y<span class="sc">-</span>par)));</span>
<span id="cb51-4"><a href="estimatesProperties.html#cb51-4" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb51-5"><a href="estimatesProperties.html#cb51-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-6"><a href="estimatesProperties.html#cb51-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">optim</span>(<span class="fu">mean</span>(y), <span class="at">fn=</span>estimator, <span class="at">method=</span><span class="st">&quot;Brent&quot;</span>, <span class="at">lower=</span><span class="fu">min</span>(y), <span class="at">upper=</span><span class="fu">max</span>(y)));</span>
<span id="cb51-7"><a href="estimatesProperties.html#cb51-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-8"><a href="estimatesProperties.html#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="estimatesProperties.html#cb51-9" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb51-10"><a href="estimatesProperties.html#cb51-10" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb51-11"><a href="estimatesProperties.html#cb51-11" aria-hidden="true" tabindex="-1"></a>nIterations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb51-12"><a href="estimatesProperties.html#cb51-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10000</span>, mu, sigma)</span>
<span id="cb51-13"><a href="estimatesProperties.html#cb51-13" aria-hidden="true" tabindex="-1"></a>LMaxEstimates <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;numeric&quot;</span>, nIterations)</span>
<span id="cb51-14"><a href="estimatesProperties.html#cb51-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nIterations){</span>
<span id="cb51-15"><a href="estimatesProperties.html#cb51-15" aria-hidden="true" tabindex="-1"></a>    LMaxEstimates[i] <span class="ot">&lt;-</span> <span class="fu">LMax</span>(y[<span class="dv">1</span><span class="sc">:</span>(i<span class="sc">*</span><span class="dv">10</span>)])<span class="sc">$</span>par;</span>
<span id="cb51-16"><a href="estimatesProperties.html#cb51-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>And here how the estimate looks with the increase of sample size:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="estimatesProperties.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span>nIterations<span class="sc">*</span><span class="dv">10</span>, LMaxEstimates, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Sample size&quot;</span>,<span class="at">ylab=</span><span class="fu">TeX</span>(<span class="st">&quot;Estimate of $</span><span class="sc">\\</span><span class="st">mu$&quot;</span>))</span>
<span id="cb52-2"><a href="estimatesProperties.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span>mu, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:statsConsistency"></span>
<img src="images/02-statistics-consistency.png" alt="An example of inconsistent estimator."  />
<p class="caption">
Figure 4.6: An example of inconsistent estimator.
</p>
</div>
<p>While in the example with bias we could see that the lines converge to the red line (the true value) with the increase of the sample size, the Chebyshev metric example shows that the line does not approach the true one, even when the sample size is 10000 observations. The conclusion is that when Chebyshev metric is used, it produces inconsistent estimates of parameters.</p>
<div class="remark">
<p><span id="unlabeled-div-1" class="remark"><em>Remark</em>. </span>There is a prejudice in the world of practitioners that the situation in the market changes so fast that the old observations become useless very fast. As a result many companies just through away the old data. Although, in general the statement about the market changes is true, the forecasters tend to work with the models that take this into account (e.g.Â Exponential smoothing, ARIMA, discussed in this book). These models adapt to the potential changes. So, we may benefit from the old data because it allows us getting more consistent estimates of parameters. Just keep in mind, that you can always remove the annoying bits of data but you can never un-throw away the data.</p>
</div>
</div>
<div id="asymptoticNormality" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Asymptotic normality</h3>
<p>Finally, <strong>asymptotic normality</strong> is not critical, but in many cases is a desired, useful property of estimates. What it tells us is that the distribution of the estimate of parameter will be well behaved with a specific mean (typically equal to <span class="math inline">\(\mu\)</span>) and a fixed variance. This follows directly from <a href="#LLNandCLT">CLT</a>. Some of the statistical tests and mathematical derivations rely on this assumption. For example, when one conducts a significance test for parameters of model, this assumption is implied in the process. If the distribution is not Normal, then the confidence intervals constructed for the parameters will be wrong together with the respective t- and p- values.</p>
<p>Another important aspect to cover is what the term <strong>asymptotic</strong>, which we have already used, means in our context. Here and after in this book, when this word is used, we refer to an unrealistic hypothetical situation of having all the data in the multiverse, where the time index <span class="math inline">\(t \rightarrow \infty\)</span>. While this is impossible in practice, the idea is useful, because asymptotic behaviour of estimators and models is helpful on large samples of data. Besides, even if we deal with small samples, it is good to know what to expect to happen if the sample size increases.</p>
</div>
<div id="efficiencyVSBias" class="section level3" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Why having biased estimate can be better than having the inefficient one?</h3>
<p>It might not be clear to everyone why the model with some bias in it might be better than the model with high variance. In order to answer this question, consider the situation, where we want to estimate the value of parameter <span class="math inline">\(\mu\)</span>, and we have two methods to do that. Given that we work on a sample of data, the estimates will have some sorts of distributions, shown in Figure <a href="estimatesProperties.html#fig:biasVarianceEstimate">4.7</a>.</p>
<div class="figure"><span style="display:block;" id="fig:biasVarianceEstimate"></span>
<img src="adam_files/figure-html/biasVarianceEstimate-1.png" alt="Example of two estimators of a parameter." width="672" />
<p class="caption">
Figure 4.7: Example of two estimators of a parameter.
</p>
</div>
<p>Which of the two estimators would you prefer: the first one or the second one? The conventional statistician might choose Estimator 1, because it produces the unbiased estimates of parameter, meaning that on average we will have the correct value of the true parameter. However, if we rephrase the question slightly, making it more realistic, the answer would probably change: âWhich of the two estimators would you prefer <strong>on small sample</strong>?â In this situation, we understand that we have limited data and need to make a decision based on what we have on hands, we might not be able to rely on asymptotic properties, on LLN and CLT (Chapter <a href="PopulationSampling.html#PopulationSampling">4</a>). If we choose Estimator 1, then on our specific sample, we might end up easily with a value for <span class="math inline">\(m\)</span> of -2, 0 or 6, just due to the pure chance - this is how wide the distribution is. On the other hand, if we choose the Estimator 2, we will end up with the value, which will be close to the true one: 2.5, 3 or 4. Yes, this value will be typically higher than needed, but at least it will not lead us to confusing conclusions on the data we have. Having said that, if the bias was too high (e.g.Â if the distribution of the Estimator 2 was placed around -4), the estimator might become unreliable, so there should be some balance in how much bias one should impose.</p>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Example 4.1  </strong></span>In a computer game Diablo II (by Blizzard North), there are two spells, which might be considered as similar in terms of damage to monsters: Lightning and Glacial Spike. On the first level, the Lightning does random damage from 1 to 43, while the Glacial Spike does randomly 17 to 26. Assuming that the distributions of damage are uniform in both cases, we would conclude that on average the Lightning does slightly more damage than the Glacial Spike: <span class="math inline">\(\frac{1}{2}(43+1)=22\)</span> vs <span class="math inline">\(\frac{1}{2}(17+26)=21.5\)</span>. However, the Lightning has much higher variability, and is less efficient in killing monsters than the Glacial Spike: it has variance of <span class="math inline">\(\frac{1}{12}(43-1)^2 = 147\)</span> versus <span class="math inline">\(\frac{1}{12}(26-17)^2 = 6.75\)</span> of the Glacial Spike. This means that each time a player shoots the Lightning, there is a chance that it will do less damage than the Glacial Spike (for example, in <span class="math inline">\(\frac{(17-1)}{(43-1)} \approx 38\)</span>% of the cases Lightning will do less damage than the lowest possible damage of the Glacial Spike). This means that if one needs to choose, which of the spells to use in a battle, the Glacial Spike would be a safer option, as each specific shot will not be as weak as it could be in the case of the Lightning. But if a player casts both spells many times, then asymptotically the Lightning will be better than Glacial Spike, as it would do more damage on average.</p>
</div>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-WikipediaVarianceBias2020" class="csl-entry">
â¢ Wikipedia, 2020a. Bias of estimator: Sample variance. <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator#Sample_variance">https://en.wikipedia.org/wiki/Bias_of_an_estimator#Sample_variance</a> (version: 2020-08-12)
</div>
<div id="ref-WikipediaMedianEfficiency2020" class="csl-entry">
â¢ Wikipedia, 2020b. Efficiency (statistics): Asymptotic efficiency. <a href="https://en.wikipedia.org/wiki/Efficiency_(statistics)#Asymptotic_efficiency">https://en.wikipedia.org/wiki/Efficiency_(statistics)#Asymptotic_efficiency</a> (version: 2020-08-12)
</div>
</div>

            </section>

          </div>
        </div>
      </div>
<a href="CLT.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="uncertaintyData.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/config-i1/adam/tree/master/Chapters//06-population-sampling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adam.pdf", "adam.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
