# Probability theory {#probabilityTheory}
Before moving to the discussion of statistics, we need to understand the basics of probability theory. In this chapter we will discuss the definition of probability, the definition of random variable then addition and multiplication of probabilities, conditional and independent probabilities and finally the Bayes' Theorem. All these theoretical ideas form the basis of more advanced statistical tools, which is why they are important.


## What is probability? {#whatIsProbability}
We start with a classical example: tossing a coin. If you have one, take it in your hands, look at it, and answer a question: what outcome will you have if you toss it? Toss it once and, let's say, it ended up showing heads. Can you predict the outcome of the next toss based on this observation? What if you toss it again and end up with tails? Would that change your prediction for the next toss?

What we could do in this situation to predict future outcomes is to write down the results of tosses as zeroes (for heads) and ones (for tails). We will then have a set of observations of a style:

1 0 1 0 0 1 1 0 1 1

If we then take the mean of this series, we will see that the expected outcome based on our sample is 0.6. We would call this value the **empirical probability**. It shows us that roughly in 50% of the cases in our sample we get tails. But this is based on just 10 experiments. If we continue tossing the coin for many more times, this probability (in the case of a fair coin) will eventually converge to 0.5, meaning that in the 50% of the cases the coin will show heads and in the other 50% it will be tails. In fact, we know that there are only two possible outcomes in this experiment, and that in case of a fair coin, there are no specific forces that could change the outcome and lead to more tails than heads. In this case, we can say that the **theoretical probability** of having tails is 0.5. Note that this does not tell us anything about each specific outcome, but only demonstrates what happens on average, when we repeat the experiment many times.

::: definition
Probability is the measure of how likely an event is expected to occur if we observe it many times.
:::

This definition implies that we cannot tell what the next outcome of the experiment will be (whether the coin toss will result in heads or tails). Instead, we can say what will happen on average if the experiment is repeated many times. By definition, the probability lies between 0 and 1, where 0 means that the event will not occur and 1 implies that it will always occur.

::: remark
When interpreting the probability, we can never say whether the event will happen or not unless the probability equals exactly to 0 or 1. For example, if the probability of rain today is 0.05, this does not mean that we will not have rain today. It only means that if this day repeats many times, in 5% of them it will rain. And there is no guarantee that today we will have one of those 95% sunny days.
:::

We could do other similar experiments, for example rolling a six-sided dice, and calculating the probability of a specific outcome. In the simple cases with coins, cards, dices etc, we can even tell the probability without running the experiments. All we need to do is calculate the number of outcomes of interest and divide it by the sum of all the possible outcomes. For example, the probability of getting 3 on a 6-sided dice is $\frac{1}{6}$, because there are overall six outcomes: 1, 2, 3, 4, 5 and 6, and the probability of getting any one of them is the same for all of them (if the dice is fair). The probability of getting 5 is $\frac{1}{6}$ as well for the same reason: all the six outcomes are considered equally possible and will happen **on average** every sixth roll.

::: remark
In some tabletop games, the number of dices and their outcomes are encoded as $a \mathrm{d} b$, where $a$ is the number of dices, $b$ is the number of sides and d stands for the word "dice". In our example, the 10-sided dice can be encoded as 1d10, while the classical 6-sided one is 1d6.
:::

Mathematically, we will denote probability as $\mathrm{P}(y)$, where $y$ represents a specific outcome. We can write, for example, that the probability of having 3 in the dice roll experiment is:
\begin{equation}
    \mathrm{P}(y=3) = \frac{1}{6} .
    (\#eq:ProbabilityExample01)
\end{equation}
We can calculate more complicated probabilities. For example,  what is the probability of having an odd number when rolling a 1d6? We need to calculate the number of events of interest and divide that number by the number of possible outcomes. In our case, the former is 1, 3, and 5 (three numbers), while the latter is any integer number from 1 to 6 (six numbers). This means that:
\begin{equation}
    \mathrm{P}(y \text{ is odd}) = \frac{3}{6} = \frac{1}{2}.
    (\#eq:ProbabilityExample02)
\end{equation}


<!-- Definitions of outcome, random event,  -->


## What is random variable? {#whatIsRandomVariable}
We have already discussed what a variable is in Section \@ref(typesOfData) of this textbook. Just as a reminder, it is a symbol that represents any of a set of potential values. If the value of a variable is known in advance, then it can be considered a deterministic variable. However, if the value depends on random events (and thus is not known in advance) then such variable is called **random variable** (or stochastic variable). In Section \@ref(whatIsProbability) we discussed the idea of probability and random events with example of coin tossing. If we continue that example then we could encode the outcome of coin tossing as $y$, expecting it to take value of 0 in case of heads and 1 in case of tails. This variable would be random because the outcome of each coin toss is not known in advance.

Fundamentally speaking, the randomness appears because of the lack of information about the environment. If we knew the initial state of the coin, the power of toss and could take into account all movements of air around it and somehow control all possible uncertainties around the flight of the coin, then we would be able to predict the outcome. In that case, the event would not be random any more, and thus the variable encoding the process would be deterministic. In real life, we do not know all the factors impacting the response variable (the variable of interest) and thus we consider their impact random.

::: remark
The randomness disappears as soon as we observe the outcome of the event. For example, if we toss the coin for the first time and obtain tails, then the first value of the variable $y$ is $y_1=1$. The variable itself stays random, but the specific outcome for the first trial is not random any more.
:::

Furthermore, there are two types of random variables:

1. Discrete;
2. Continuous.

The first type represents the variable that takes count values. For example, variable $y$ for the event "coin tossing" is discrete because it can only take values of 0 and 1. Another classical example is the variable encoding the score on a 1d6, the experiment with dice roll. We cannot get a value of 4.123 in this experiment, so the variable encoding it is discrete.

The second type of random variable represents the case, when it takes non-count value, such as real number over the whole range of values or on a specific interval of values. An example of a continuous variable is the time on a stopwatch, when a runner crosses the finish line.

::: remark
The discrete variable can be considered as a continuous or approximated by the models for continuous ones when it has many outcomes. For example, the sales of wine can be measured in bottles, which is a discrete variable. But if the sales are measured in thousands of units then it might be easier to consider the variable to be continuous instead.
:::

Finally, if we want to measure the probability of random variable taking specific values, then for the discrete variable it can be done by considering the chance of that specific outcome over all possible ones. For example, for the fair dice, the chance of obtaining 3 is $\frac{1}{6}$: it can take values of 1, 2, 3, 4, 5 and 6. However, the probability that a continuous variable takes a specific value is zero, because the number of all possible cases for the continuous variable is infinite. For example, the time of a 100 meter runner can be anything between 9.2 seconds (which comes from the physics of human body) and infinity (if person never finishes). The probability that I will finish a race in 10 seconds is zero not because I am not fit enough, but rather because it is almost impossible to do that precisely on 10.000000 and not, let us say, on 10.000001.


## The Addition Law: Calculating "OR" Probability {#probabilityAddition}
Consider an example of a standard 52-card deck. Suppose we want to answer the question: "What is the probability of picking a card that is a face card (Jack, Queen, King) OR a spade (♠)?"

We can solve this in four clear steps:

1. Calculate $P(F)$: First, we calculate the probability of picking a face card. There are 3 face cards in each of the 4 suits, giving a total of 12 face cards. $P(F) = \frac{12}{52}$
2. Calculate $P(S)$: Next, we calculate the probability of picking a spade. There are 13 spades in the deck. $P(S) = \frac{13}{52}$
A common mistake is to simply add these two probabilities together. However, this would lead to an error because some cards satisfy both conditions and would be counted twice.
3. Identify the intersection $P(F \text{ AND } S)$: We must identify the cards that are both a face card and a spade. These are the Jack of Spades (J♠), the Queen of Spades (Q♠), and the King of Spades (K♠). There are 3 such cards. The probability of this intersection is: $P(F \text{ AND } S) = \frac{3}{52}$
4. Calculate the final probability $P(F \text{ OR } S)$: To find the correct probability, we add the individual probabilities and then subtract the intersection to correct for the double-counting. $P(F \text{ OR } S) = \frac{12}{52} + \frac{13}{52} - \frac{3}{52} = \frac{22}{52}$. Simplifying this fraction gives us our final answer: $\frac{11}{26}$.

::: remark
The "AND" and "OR" operators in mathematics, are typically denote by symbols of intersection and union respectively: $P(F \text{ AND } S) = P(F \cap S)$, $P(F \text{ OR } S) = P(F \cup S)$.
:::

### The General Addition Law
The Addition Law is our primary tool for calculating the probability of at least one of two or more events occurring. We use it when we are interested in the likelihood of outcome A or outcome B happening. This principle is of immense strategic importance in business scenarios where multiple successful outcomes are possible. For example, in risk assessment, it helps calculate the probability of a project being delayed by any one of several potential factors. As an analyst, you will constantly be asked to evaluate scenarios with multiple paths to success; mastering the Addition Law is your first step towards providing a statistically sound answer.

The process we followed in the card example leads us to the formal rule. The **General Addition Law for Probabilities** is stated as:
\begin{equation}
    P(A \cup B) = P(A) + P(B) - P(A \cap B) 
    (\#eq:ProbAdditionLaw)
\end{equation}

This concept is easily visualised using a Venn diagram shown in Figure \@ref(fig:vennDiagramCard01).

```{r vennDiagramCard01, echo=FALSE, fig.cap="Venn diagram for the cards example."}
# Set up a blank plot
plot(1, type="n", xlim=c(4,5), ylim=c(1,7), axes=FALSE, xlab="", ylab="", asp=1)

# Draw the two circles
symbols(3, 4, circles=3, inches=FALSE, add=TRUE, fg=2, bg=8)
symbols(6, 4, circles=3, inches=FALSE, add=TRUE, fg=4, bg=10)

# Add text
# Add text to the left circle ("F=12")
text(1.5, 4, "F=12", cex=1.2, col=2)

# Add text to the right circle ("S=13")
text(7.2, 4, "S=13", cex=1.2, col=4)

# Add intersection
text(4.5, 4, TeX("$P(F \\cap S)=3$"), cex=1.2, col=1)
```

::: remark
The union ($F \cup S$) in Figure \@ref(fig:vennDiagramCard01) corresponds to the overall area of the two circles, while the intersection ($F \cap S$) corresponds to the common area between the two circles.
:::

Figure \@ref(fig:vennDiagramCard01) shows the number of Face cards (12) in the red area, Spades cards (13) in the blue area, and their intersection in the purple area between them. The overlapping area, $(F \cap S)$, represents those three specific cards that are both face and spades. The formula's subtraction term, - $P(A \cap B)$, is simply the mathematical step we take to remove that single layer of double-counting.

### Special Case: Mutually Exclusive Events
There is a simpler version of the Addition Law that applies to a special category of events. Mutually exclusive events are events that cannot both happen at the same time; their intersection is zero.

Consider this question: "What is the probability of picking either a Jack or a Queen (of any suit)?"

These two events are mutually exclusive because a single card cannot be both a Jack and a Queen at the same time. This situation can be shown in the Venn diagram in Figure \@ref(fig:vennDiagramCard02).

```{r vennDiagramCard02, echo=FALSE, fig.cap="Venn diagram for the cards example with mutually exclusive events."}
# Set up a blank plot
plot(1, type="n", xlim=c(4,5), ylim=c(1,7), axes=FALSE, xlab="", ylab="", asp=1)

# Draw the two circles
symbols(1, 4, circles=3, inches=FALSE, add=TRUE, fg=2, bg=8)
symbols(7.2, 4, circles=3, inches=FALSE, add=TRUE, fg=4, bg=10)

# Add text
text(1, 4, "J=4", cex=1.2, col=2)
text(7.2, 4, "Q=4", cex=1.2, col=4)
```

Since there is no overlap, the intersection term $P(A \cap B)$ is zero. The calculation is therefore a simple sum:
\begin{equation*}
    P(J \cup Q) = P(J) + P(Q) = \frac{4}{52} + \frac{4}{52} = \frac{8}{52} = \frac{2}{13}.
\end{equation*}

This leads to the **Addition Law for Mutually Exclusive Events**:
\begin{equation}
    P(A \cup B) = P(A) + P(B).
    (\#eq:ProbAdditionLawME)
\end{equation}


## Multiplication of probabilities: Calculating "AND" Probability {#probabilityMultiplication}
Consider an example: Jane has a 0.7 probability of writing a page of coursework with no spelling mistakes. This means she has a 0.3 probability of making at least one mistake on a given page. She is writing a 3-page assignment, and what happens on the first page in no way affects what happens on the other pages. What is the probability that she will have no spelling mistakes on at least one of the three pages?

To answer this question, we need to use the Multiplication Law. In this specific example, we can use the simplified version of it because the events (a mistake on a page) are independent (as stated in the setting above).

::: definition
**Independent events** are the events where the occurrence of one has no influence on the probability of the other.
:::


### Independent Events
Calculating the probability of "at least one" success implies that Jane made no mistakes in one of these situations:

1. No mistakes on all three pages;
1. Mistake on exactly one page: either the first, the second, or the third;
2. Mistakes on exactly two pages: either first and second, or first and third, or second and third.

Calculating all probabilities and summing them up is cumbersome. Luckily, there is a simpler way of getting the answer: to use the complement rule, which states that the probability of an event happening is 1 minus the probability of it not happening. In our case, the "not happening" means that Jane will have spelling mistakes on every page (this is the only other option left). Mathematically it can be written down as:

\begin{equation*}
    P(\text{No mistakes on at least one page}) = 1 - P(\text{Mistakes on all pages})
\end{equation*}

To calculate the probability of the complementary event (mistakes on all 3 pages), we can use the **Multiplication Law**. Given that the events are *independent*, all we need to do is multiply the probability of having a mistake on the first page by the probability of having a mistake on the second and then the probability of having a mistake on the third page:

\begin{equation*}
    P(\text{Mistakes on all pages}) = P(M_1 \cap M_2 \cap M_3) = P(M_1) × P(M_2) × P(M_3) = 0.3 × 0.3 × 0.3 = 0.3^3 = 0.027.
\end{equation*}

After that, we can the complement rule to answer the original question: 

\begin{equation*}
    P(\text{No mistakes on at least one page}) = 1 - P(\text{Mistakes on all pages}) = 1 -0.027 = 0.973
\end{equation*}

So, there is a 97.3% chance that at least one page will be free of spelling mistakes. This example illustrates the **Multiplication Law for Independent Events**, which can be written mathematically as:
\begin{equation}
    P(A \cap B) = P(A) \times P(B) .
    (\#eq:ProbmultiplicationLawIndep)
\end{equation}

Visually, we could draw a Venn diagram to understand what specific area we are talking about when we use the multiplication law (Figure \@ref(fig:vennDiagramThree)).


```{r vennDiagramThree, echo=FALSE, fig.cap="Venn diagram for three events.", fig.height=6}
# Set up a blank plot
plot(1, type="n", xlim=c(4,5), ylim=c(1,10), axes=FALSE, xlab="", ylab="", asp=1)

# Draw the two circles
symbols(2, 4, circles=3, inches=FALSE, add=TRUE, fg=2, bg=8)
symbols(4, 7, circles=3, inches=FALSE, add=TRUE, fg=3, bg=9)
symbols(6, 4, circles=3, inches=FALSE, add=TRUE, fg=4, bg=10)

# Add 
text(9, 8, "All three events", cex=1.2, col=1, pos=3)
segments(4, 5, 9, 8)

text(2, 4, "Event A", cex=1.2, col=2, pos=2)
text(4, 7, "Event B", cex=1.2, col=3, pos=3)
text(6, 4, "Event C", cex=1.2, col=4, pos=4)
```

In that diagram, the multiplication corresponds to the area in the intersection of circles. If the events are independent, the outcome "every page contains a mistake" corresponds to the area for "all three events", i.e. $P(A \cap B \cap C) = P(A) \times P(B) \times P(C)$, as we saw in the example above.


### Dependent Events and Conditional Probability
The situation changes when we deal with dependent events, where the outcome of the first event impacts the probability of the second.

Consider another example: in a class of 6 students, 4 are secretly vampires. The teacher randomly chooses 2 students. What is the probability that neither of the two chosen students are vampires?

These events are dependent because as soon as the teacher chooses one student, the sample size changes and the probabilities for the rest would change. This is called "**sampling without replacement**". The selection of the first student changes the composition of the group from which the second student is chosen. To handle this, we must use **Conditional Probability**.

To better understand the situation, we can draw a tree diagram, which depicts the possible situations (Figure \@ref(fig:treeForVampire)).

```{r treeForVampire, fig.height=6, echo=FALSE, fig.cap="Tree diagram for the vampire example."}
# Set up blank plot
plot(1, type="n", xlim=c(0,10), ylim=c(1,10), axes=FALSE, xlab="", ylab="")

# Core node (left)
points(1, 5, pch=21, bg=15, cex=2)

text(0.5, 5.7, "6 students", cex=1.3)

# First layer of branches: p1 and p2
segments(1, 5, 3, 7, lwd=2)  # p1 - upper path
segments(1, 5, 3, 3, lwd=2)  # p2 - lower path
points(3, 7, pch=21, bg=3, cex=2)
points(3, 3, pch=21, bg=4, cex=2)

text(3.1, 10, "The first one is:", cex=1.3, col=1)
text(3.1, 8, "Vampire", cex=1.1, col=3)
text(3.1, 4, "Not Vampire", cex=1.1, col=4)

text(1.9, 7, TeX("$P(V) = \\frac{4}{6}$"), cex=1.1, col=3)
text(1.9, 3, TeX("$P(NV) = \\frac{2}{6}$"), cex=1.1, col=4)

# Second layer of branches: p3 and p4 from each branch
segments(3, 7, 6, 8, lwd=2)  # p3 from p1
segments(3, 7, 6, 6, lwd=2)  # p4 from p1
segments(3, 3, 6, 4, lwd=2)  # p3 from p2
segments(3, 3, 6, 2, lwd=2)  # p4 from p2

text(6, 10, "The second one is:", cex=1.3, col=1)

points(6, 8, pch=21, bg=7, cex=2)
text(6, 8, "Vampire", cex=1.1, col=7, pos=4)
points(6, 6, pch=21, bg=6, cex=2)
text(6, 6, "Not Vampire", cex=1.1, col=6, pos=4)
points(6, 4, pch=21, bg=7, cex=2)
text(6, 4, "Vampire", cex=1.1, col=7, pos=4)
points(6, 2, pch=21, bg=6, cex=2)
text(6, 2, "Not Vampire", cex=1.1, col=6, pos=4)

# Probabilities
text(4.5, 8.5, TeX("$P(V) = \\frac{3}{5}$"), cex=1.1, col=7)
text(5, 5.5, TeX("$P(NV) = \\frac{2}{5}$"), cex=1.1, col=6)
text(4.5, 4.4, TeX("$P(V) = \\frac{4}{5}$"), cex=1.1, col=7)
text(5, 1.5, TeX("$P(NV) = \\frac{1}{5}$"), cex=1.1, col=6)
```

In this diagram, when we pick the first student, we reduce the pool of the students to choose from from 6 to 5. This also changes the probabilities for students being and not being vampires, depending on whom we picked in the first step. The probabilities on the second step now become **conditional** on the choice made in the first step and are denoted in general as $P(A|B)$, which can be read as "probability of the outcome A, given the outcome B". In our terms, we can denote, for example, the probability that the student is not a vampire, given that the first one was not a vampire, as $P(NV_2 | NV_1)$.

Using the Multiplication law, we need to take the probability of a student being not a vampire in the first step and multiply it by the probability of the student not being a vampire in the second step, given that the first one was not a vampire. Mathematically, it can be written:

\begin{equation*}
    P(NV_1) \times P(NV_2 | NV_1) = \frac{2}{6} \times \frac{1}{5} = \frac{2}{30} = \frac{1}{15} \approx 0.067.
\end{equation*}

So the probability of picking two non-vampire students in our example is only 6.7%.


### General Multiplication Law
The Multiplication Law is used to determine the probability of two or more events occurring in sequence or simultaneously - an 'AND' scenario. In business, success often depends on a chain of events, where every link must hold. The Multiplication Law is the tool we can use to quantify the probability of that entire chain succeeding, whether in quality control, financial modelling, or project management. Mathematically, we use the notation $P(B|A)$ to represent "the probability of event B occurring, given that event A has already occurred".

The dependent events example leads us to the formal statement of the general rule.

The General Multiplication Law for Probabilities is written mathematically as:
\begin{equation}
    P(A \cap B) = P(B) \times P(A|B) .
    (\#eq:ProbmultiplicationLaw)
\end{equation}
In case of the independence, the conditional probability becomes just an unconditional one: $P(A|B)=P(A)$.

By algebraically rearranging formula \@ref(eq:ProbmultiplicationLaw), we arrive at the formal definition of **Conditional Probability**:
\begin{equation}
    P(A|B) = \frac{P(A \cap B)} P(B).
    (\#eq:conditionalProb)
\end{equation}

This rearrangement is more than just algebra; it provides the fundamental definition of conditional probability. It defines the probability of "A given B" as the proportion of B outcomes that also include A. Visually, this can be shown in Figure \@ref(fig:vennDiagramConditional). There, there conditional probability of A given B would correspond to the proportion of the areas $A \cap B$ (intersection of events) to the overall area of B.

```{r vennDiagramConditional, echo=FALSE, fig.cap="Venn diagram for the conditional probability explanation."}
# Set up a blank plot
plot(1, type="n", xlim=c(4,5), ylim=c(1,7), axes=FALSE, xlab="", ylab="", asp=1)

# Draw the two circles
symbols(3, 4, circles=3, inches=FALSE, add=TRUE, fg=2, bg=8)
symbols(6, 4, circles=3, inches=FALSE, add=TRUE, fg=4, bg=10)

# Add text
# Add text to the left circle ("F=12")
text(2.5, 4, "A", cex=1.2, col=2, pos=2)

# Add text to the right circle ("S=13")
text(6.5, 4, "B", cex=1.2, col=4, pos=4)

# Add intersection
text(4.5, 4, TeX("$A \\cap B$"), cex=1.2, col=1)
```


## The Law of Total Probability {#totalProbability}
### Example: Faulty Goods in a Factory

A chocolate factory has four production lines, each contributing a different percentage to the total output and having its own unique fault rate. These are summarised in the table below:

| Line        |   A   |   B   |   C   |   D   |
|:-----------:|:-----:|:-----:|:-----:|:-----:|
| % Faulty    |  1    |  3    |  2.5  |  2    |
| % Output    |  35   |  20   |  24   |  21   |

The management wants to understand what is the probability that a box chosen at random from the factory's output is faulty?

To solve this, we must recognise that a faulty box can come from one of the four lines:

1. line A,
2. or line B,
3. or line C,
4. or line D.

These are mutually exclusive pathways. The total probability of a faulty box, P(F), is therefore the sum of the probabilities of a box being:
1. faulty and from line A,
2. faulty and from line B,
3. faulty and from line C,
4. faulty and from line D.

We are interested in calculating the overall probability $P(F)$, which is just a simple sum of four intersections:
\begin{equation*}
    P(F) = P(F \cap A) + P(F \cap B) + P(F \cap C) + P(F \cap D),
\end{equation*}
because the events are *mutually exclusive* and a faulty chocolate box can come only from one of four lines. So, we need to calculate the joint probabilities for each line, which can be done using the General Multiplication Law. For example, for line A:
\begin{equation*}
    P(F \cap A) = P(F|A) \times P(A).
\end{equation*}
Similar formulae can be used for the lines B, C and D. Inserting the available probabilities, we get:

- Probability of a faulty box from Line A: $P(F \cap A) = 0.01 \times 0.35 = 0.0035$
- Probability of a faulty box from Line B: $P(F \cap B) = 0.03 \times 0.20 = 0.0060$
- Probability of a faulty box from Line C: $P(F \cap C) = 0.025 \times 0.24 = 0.0060$
- Probability of a faulty box from Line D: $P(F \cap D) = 0.02 \times 0.21 = 0.0042$

And after that, we can sum these up to get the answer:
\begin{equation*}
    P(F) = 0.0035 + 0.0060 + 0.0060 + 0.0042 = 0.0197
\end{equation*}
So, the probability of a randomly chosen box being faulty is 1.97%.

### Formalising the Law of Total Probability
The Law of Total Probability is a law, explaining how the probability of an event can be found by considering all the different, mutually exclusive ways it can occur. This is a cornerstone of strategic thinking. When you need to find an overall probability but your data is broken down by different scenarios or categories, this law shows you how to piece it all together. Its importance lies in its ability to aggregate risk and information.

The factory example provides an illustration of the general formal rule. The Law of Total Probability states that if events $A_1, A_2, \dots, A_n$ are *mutually exclusive and collectively exhaustive* (meaning they cover all possibilities), then the probability of another event B can be calculated by weighing and summing the conditional probabilities of B:
\begin{equation}
    P(B) = P(B|A_1) \times P(A_1) + P(B|A_2) \times P(A_2) + \dots + P(B|A_n) \times P(A_n)
    (\#eq:ProbTotal)
\end{equation}
This can also be interpreted as the sum of intersections of probabilities.

This law provides a fundamental bridge to more advanced concepts, most notably Bayes' Theorem (discussed in Section \@ref(BayesTheorem)), by allowing for the calculation of an overall (or marginal) probability from a set of conditional probabilities.



## Bayes' theorem {#BayesTheorem}
One of the common problems we have faced at some point of our online lives is the problem of detecting spam. Consider a situation motivated by the real life scenario, where we track the words in the received emails and depending on some of them, we can assign probability of the email being or not being spam. If this probability is higher than some pre-specified threshold, we can then filter out the message and do efficient spam detection. This is in essence what many mail agents do under the hood, although our case is a crude simplification.

But before we even look at the new email, we have some existing information based on the general flow of emails. This is our initial, or "prior" belief about the probability of an email being spam. We assume the following for this example:

* The probability that any given email is spam: P(Spam) = 0.4 (or 40%)
* The probability that any given email is not spam: P(Not Spam) = 0.6 (or 60%)

We assume that this is the case for our toy example, although in real life these can differ substantially. Next, we have information derived from a large set of training data. This data tells us how frequently the word "discount" appears in emails that are known to be spam versus those that are not. These are our conditional probabilities:

* The probability of seeing the word "discount" given the email is spam: P("discount"|Spam) = 0.7 (or 70%)
* The probability of seeing the word "discount" given the email is not spam: P("discount"|Not Spam) = 0.1 (or 10%)

Now, the main question of interest for us is to understand what is the probability that an email is spam if the word 'discount' appears in it. i.e. we need to find P(Spam | "discount").

But how can we do that?

If we take a step back and come back to the multiplication law from Section \@ref(probabilityMultiplication), we will notice that in the example we had, we can work out the final probability equally in any sequence: if we first have event B and then event A, or if we we have first A and then B. In our example with vampires, the order did not matter (the first student becomes first no matter what). But in general, this means that the probability of this joint outcome can be calculated in one of two possible ways:
\begin{equation}
    P(A \cap B) = P(B) \times P(A|B) = P(A) \times P(B|A) .
    (\#eq:ProbmultiplicationLawJoint)
\end{equation}

For the example at hand, this can be written with events $S$ for the message being spam and "D" denoting the presence of the word "discount" (for brevity):
\begin{equation*}
    P(S \cap D) = P(D) \times P(S|D) = P(S) \times P(D|S) ,
\end{equation*}
which means that the probability of the email containing the word "discount" and being spam given that it contains that word is the same as the probability of the email being spam and containing the word "discount" given that it is spam. This is useful because we can use this equality for our calculations to get the inverse probability we need by regrouping the elements in the equation to:

\begin{equation}
    P(S|D) = \frac{P(S) \times P(D|S)}{P(D)} .
    (\#eq:BayesInExample)
\end{equation}
Equation \@ref(eq:BayesInExample) is called the Bayes' equation and allows getting the "posterior" probability ($P(S|D)$) given the prior ($P(S)$) and some new information ($P(D|S)$ and $P(D)$).

In our case, we have all the probabilities to insert in \@ref(eq:BayesInExample):

1. $P(S) = 0.4$;
2. $P(D|S) = 0.7$;
3. $P(D) = P(D|S) P(S) + P(D|NS) P(NS) = 0.7 \times 0.4 + 0.1 \times 0.6 = 0.34$ - due to the Law of Total Probability discussed in Section \@ref(totalProbability).

Inserting these values in the formula \@ref(eq:BayesInExample) gives us the answer:
\begin{equation*}
    P(S|D) = \frac{0.4 \times 0.7}{0.34} \approx 0.82 .
    (\#eq:BayesInExample)
\end{equation*}

This resulting probability tells us that there is approximately an 82% chance that the email is spam if it contains the word "discount". Notice how observing this single word has allowed us to update our belief. We started with a prior probability of 40% and, after considering the evidence, have arrived at a revised ("posterior") probability of 82%. If we set the threshold for filtering the emails as spam, for example, to 80%, any email that would contain the word "discount" would be flagged as one. In reality, the detection systems would rely on sequences of words (tokens) instead of just one word, and the specific probabilities would differ from the ones we used above. But the main principles of the Bayes' theorem would hold.

### Mathematical derivation
The theorem's origins trace back to the work of the Reverend Thomas Bayes, whose work "An Essay Toward Solving a Problem in the Doctrine of Chances" was published posthumously in 1764 [@Bayes]. The derivation begins with the multiplication law for two events, A and B, which states that the probability of both events occurring together can be expressed in two ways (as we saw in equation \@ref(ProbmultiplicationLawJoint)):
\begin{equation*}
    P(A \cap B) = P(B) \times P(A|B) = P(A) \times P(B|A) .
\end{equation*}
From this equality, we can isolate P(A|B) through simple algebraic rearrangement to arrive to the fundamental form of Bayes' theorem:
\begin{equation}
    P(A|B) = \frac{P(A) \times P(B|A)}{P(B)} .
    (\#eq:BayesInExample)
\end{equation}

Each component of the theorem has a specific name and plays a distinct role in the process of updating our beliefs. This structure is what makes the theorem so powerful for statistical inference.

1. Posterior Probability	$P(A | B)$;
2. Conditional Probability $P(B | A)$;
3. Prior Probability $P(A)$;
4. Marginal Probability	$P(B)$.

The probability (3) is the initial probability of event A occurring, based on existing information before the new evidence is considered. The marginal probability $P(B)$ is the overall probability of observing the new information B. This is often called the evidence or normalising constant. It ensures that the final posterior probabilities sum to 1, by accounting for the overall probability of observing the evidence across all possible hypotheses.
